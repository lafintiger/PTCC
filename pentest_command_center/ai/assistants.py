import json
import sys
import os
from typing import Dict, List, Any, Optional

# Add parent directory to path so we can import from config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from ai.ollama_client import OllamaClient
from ai.tool_knowledge import ToolKnowledgeBase

class PentestAssistant:
    """AI assistant for penetration testing tasks."""
    
    def __init__(self):
        self.ollama_client = OllamaClient()
        self.tool_knowledge = None  # Initialize in initialize() method
    
    async def initialize(self):
        """Initialize the assistant."""
        await self.ollama_client.initialize()
        self.tool_knowledge = ToolKnowledgeBase(self.ollama_client)
        
        # Optionally initialize the model with tool knowledge
        # Commented out by default, but can be enabled for production
        # await self.initialize_model_with_knowledge()
    
    async def close(self):
        """Clean up resources."""
        await self.ollama_client.close()
    
    async def analyze_network_scan(self, scan_results: Dict[str, Any], additional_instructions: str = "") -> str:
        """Analyze network scan results with optional additional instructions."""
        return await self.ollama_client.analyze_scan_results(scan_results, "network", additional_instructions)
    
    async def analyze_vulnerability_scan(self, scan_results: Dict[str, Any], additional_instructions: str = "") -> str:
        """Analyze vulnerability scan results with optional additional instructions."""
        return await self.ollama_client.analyze_scan_results(scan_results, "vulnerability", additional_instructions)
    
    async def analyze_port_scan(self, scan_results: Dict[str, Any]) -> str:
        """Analyze port scan results."""
        return await self.ollama_client.analyze_scan_results(scan_results, "port")
    
    async def recommend_next_steps(self, current_findings: Dict[str, Any]) -> str:
        """Recommend next steps based on current findings."""
        prompt = f"""
        Based on the following current findings, recommend the next steps in the penetration testing process:
        
        {json.dumps(current_findings, indent=2)}
        
        Provide:
        1. Specific next steps
        2. Tools to use for each step
        3. Expected outcomes
        """
        
        return await self.ollama_client.generate_text(prompt)
    
    async def generate_attack_plan(self, target_info: Dict[str, Any]) -> str:
        """Generate an attack plan based on target information."""
        prompt = f"""
        Generate a comprehensive attack plan for the following target:
        
        {json.dumps(target_info, indent=2)}
        
        The plan should include:
        1. Reconnaissance steps
        2. Scanning methodology
        3. Potential vulnerabilities to look for
        4. Exploitation strategies
        5. Post-exploitation activities
        6. Covering tracks
        """
        
        return await self.ollama_client.generate_text(prompt)
    
    def parse_osint_data(self, osint_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Parse and clean OSINT data for further analysis.
        Returns a structured dictionary with categorized information.
        """
        # Build prompt for the LLM
        prompt = f"""
        Parse and structure the following OSINT data into categories:
        
        {json.dumps(osint_data, indent=2)}
        
        Return a JSON object with the following structure:
        {{
            "domains": [list of domains],
            "ip_addresses": [list of IPs],
            "emails": [list of emails],
            "social_media": [list of social media accounts],
            "technologies": [list of technologies],
            "potential_vulnerabilities": [list of potential vulnerabilities],
            "other_findings": [other notable findings]
        }}
        """
        
        # Get structured data from LLM
        try:
            response = self.ollama_client.translate_natural_language_to_command(prompt, "OSINT parsing")
            structured_data = json.loads(response)
            return structured_data
        except:
            # Fallback if parsing fails
            return {
                "domains": [],
                "ip_addresses": [],
                "emails": [],
                "social_media": [],
                "technologies": [],
                "potential_vulnerabilities": [],
                "other_findings": "Error parsing OSINT data"
            }
    
    async def explain_vulnerability(self, vulnerability_name: str) -> str:
        """Explain a vulnerability in detail."""
        prompt = f"""
        Provide a detailed explanation of the "{vulnerability_name}" vulnerability:
        
        Include:
        1. Description and technical details
        2. How it can be exploited
        3. Potential impact
        4. Remediation steps
        5. CVSS score (if applicable)
        6. Example of real-world incidents (if applicable)
        """
        
        return await self.ollama_client.generate_text(prompt)
    
    async def generate_comprehensive_report(self, all_findings: Dict[str, Any]) -> str:
        """Generate a comprehensive penetration testing report."""
        return await self.ollama_client.generate_report(all_findings)
    
    def translate_query_to_command(self, query: str, tool_context: Optional[str] = None) -> str:
        """Translate a natural language query to a specific command."""
        return self.ollama_client.translate_natural_language_to_command(query, tool_context)
    
    async def answer_tool_question(self, question: str, model: Optional[str] = None) -> str:
        """
        Answer a question about the PenTest Command Center tool
        using the tool knowledge base.
        
        Args:
            question: The question about the tool
            model: Optional specific model to use
            
        Returns:
            Answer to the question
        """
        if self.tool_knowledge is None:
            return "Tool knowledge base not initialized. Please initialize the assistant first."
        
        answer = await self.tool_knowledge.query_with_tool_context(question, model)
        return answer
    
    async def initialize_model_with_knowledge(self, model: Optional[str] = None) -> bool:
        """
        Initialize the Ollama model with the tool knowledge base.
        This should be done once, typically at the start of the application.
        
        Args:
            model: Optional specific model to initialize
            
        Returns:
            True if initialization was successful, False otherwise
        """
        if self.tool_knowledge is None:
            self.tool_knowledge = ToolKnowledgeBase(self.ollama_client)
        
        success, response = await self.tool_knowledge.initialize_model_with_knowledge(model)
        return success
    
    async def get_common_tasks_help(self) -> Dict[str, Any]:
        """
        Get help information for common tasks
        
        Returns:
            List of common tasks with steps
        """
        if self.tool_knowledge is None:
            return {"error": "Tool knowledge base not initialized"}
        
        return await self.tool_knowledge.get_knowledge_context("common_tasks")
    
    async def get_troubleshooting_help(self) -> Dict[str, Any]:
        """
        Get troubleshooting information
        
        Returns:
            List of troubleshooting solutions
        """
        if self.tool_knowledge is None:
            return {"error": "Tool knowledge base not initialized"}
        
        return await self.tool_knowledge.get_knowledge_context("troubleshooting")
