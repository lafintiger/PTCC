import json
import aiohttp
import requests
import sys
import os

# Add parent directory to path so we can import from config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.settings import OLLAMA_BASE_URL, OLLAMA_DEFAULT_MODEL

class OllamaClient:
    """Client for interacting with the Ollama API."""
    
    def __init__(self, base_url=OLLAMA_BASE_URL, default_model=OLLAMA_DEFAULT_MODEL):
        self.base_url = base_url
        self.default_model = default_model
        self.session = None
    
    async def initialize(self):
        """Initialize the aiohttp session."""
        self.session = aiohttp.ClientSession()
    
    async def close(self):
        """Close the aiohttp session."""
        if self.session:
            await self.session.close()
            self.session = None
    
    def list_models(self):
        """List available models in Ollama."""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                return response.json().get("models", [])
            return []
        except Exception as e:
            print(f"Error listing models: {e}")
            return []
    
    async def generate_text(self, prompt, model=None, temperature=0.7, max_tokens=1024):
        """Generate text using the specified model."""
        model = model or self.default_model
        
        if not self.session:
            await self.initialize()
        
        try:
            data = {
                "model": model,
                "prompt": prompt,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": False
            }
            
            async with self.session.post(f"{self.base_url}/api/generate", json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    return result.get("response", "")
                else:
                    error_text = await response.text()
                    print(f"Error from Ollama API: {error_text}")
                    return f"Error: Could not generate text with model {model}"
        except Exception as e:
            print(f"Error generating text: {e}")
            return f"Error: {str(e)}"
    
    async def analyze_scan_results(self, scan_results, scan_type, additional_instructions=""):
        """Analyze scan results and provide insights."""
        prompt = f"""
        Analyze the following {scan_type} scan results and provide:
        1. A summary of key findings
        2. Potential security implications
        3. Recommended actions

        {f"Additional analysis instructions: {additional_instructions}" if additional_instructions else ""}

        Scan Results:
        {json.dumps(scan_results, indent=2)}
        """
        
        return await self.generate_text(prompt)
    
    async def recommend_tools(self, target_description):
        """Recommend penetration testing tools based on target description."""
        prompt = f"""
        Based on the following target description, recommend specific penetration testing tools 
        and techniques that would be most effective:
        
        Target: {target_description}
        
        Provide:
        1. Recommended tools
        2. Specific scan types or techniques
        3. Order of operations
        """
        
        return await self.generate_text(prompt)
    
    async def generate_report(self, findings):
        """Generate a comprehensive report based on findings."""
        prompt = f"""
        Generate a professional penetration testing report based on the following findings:
        
        {json.dumps(findings, indent=2)}
        
        The report should include:
        1. Executive summary
        2. Methodology
        3. Detailed findings with severity ratings
        4. Recommendations for remediation
        5. Conclusion
        """
        
        return await self.generate_text(prompt, max_tokens=4096)
    
    def translate_natural_language_to_command(self, natural_language_query, tool_context=None):
        """Translate natural language to a specific tool command."""
        # Use synchronous request for simplicity in this method
        prompt = f"""
        Translate the following natural language query into a specific command:
        
        Query: {natural_language_query}
        
        Context: {tool_context or 'General penetration testing'}
        
        Return only the command without any explanation.
        """
        
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.default_model,
                    "prompt": prompt,
                    "temperature": 0.2,
                    "max_tokens": 256,
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                return response.json().get("response", "").strip()
            return f"Error: Could not translate query"
        except Exception as e:
            print(f"Error translating natural language: {e}")
            return f"Error: {str(e)}"
